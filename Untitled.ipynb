{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a074c89b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# necessary imports\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.models as models\n",
    "import torchvision.transforms as transforms \n",
    "from torchvision.utils import save_image\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e5dfdc9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequential(\n",
      "  (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (1): ReLU(inplace=True)\n",
      "  (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (3): ReLU(inplace=True)\n",
      "  (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (6): ReLU(inplace=True)\n",
      "  (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (8): ReLU(inplace=True)\n",
      "  (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (11): ReLU(inplace=True)\n",
      "  (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (13): ReLU(inplace=True)\n",
      "  (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (15): ReLU(inplace=True)\n",
      "  (16): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (17): ReLU(inplace=True)\n",
      "  (18): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (19): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (20): ReLU(inplace=True)\n",
      "  (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (22): ReLU(inplace=True)\n",
      "  (23): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (24): ReLU(inplace=True)\n",
      "  (25): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (26): ReLU(inplace=True)\n",
      "  (27): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (29): ReLU(inplace=True)\n",
      "  (30): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (31): ReLU(inplace=True)\n",
      "  (32): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (33): ReLU(inplace=True)\n",
      "  (34): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (35): ReLU(inplace=True)\n",
      "  (36): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# going to use pretrained VGG19 network\n",
    "model = models.vgg19(pretrained=True).features # it will load conv layers\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dd86be88",
   "metadata": {},
   "outputs": [],
   "source": [
    "class VGG(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(VGG, self).__init__()\n",
    "        self.features = ['0','5','10','19','28'] # we want outputs from these layers to calculate the loss\n",
    "        self.vgg_model = model\n",
    "    def forward(self,x):\n",
    "        required_layer = []\n",
    "        for layer_num, layer in enumerate(self.vgg_model):\n",
    "            x = layer(x)\n",
    "            if str(layer_num) in self.features:\n",
    "                required_layer.append(x)\n",
    "        return required_layer\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7d1e5d39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "device = 'cuda'\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "22592311",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_image(image_name):\n",
    "    image = Image.open(image_name)\n",
    "    image = loader(image).unsqueeze(0) # we are unsqueezing it to add a dimension to it to pass through the model as it requires the size (batch_size, num_channels=3, height,width)          \n",
    "    return image.to(device) #loader is basically transformed image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "963bae3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_size = 256\n",
    "loader = transforms.Compose([\n",
    "    transforms.Resize((256, 256)),\n",
    "    transforms.ToTensor()\n",
    "    # we can normalize image\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e3ee1d39",
   "metadata": {},
   "outputs": [],
   "source": [
    "content_img = load_image('ayush.jpg')\n",
    "style_img = load_image('style7.jpeg')\n",
    "#gen_image = torch.randn(content_image.shape, device = device, requires_grad = True)\n",
    "# actually generated image is the parameter\n",
    "gen_img = content_img.clone().requires_grad_(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e24e7d3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyperparameters\n",
    "num_steps = 1001\n",
    "learning_rate = 1e-3\n",
    "alpha = 1\n",
    "beta = 0.01\n",
    "optimizer = optim.Adam([gen_img], lr=learning_rate) # our only parameter is generated image, so passed it in           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b4c74840",
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining the model \n",
    "nst_model = VGG().to(device).eval() # doing so to freeze the weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ed1e29d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(54411.0391, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(28733.1582, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(19752.3594, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(14869.4121, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(11759.9873, device='cuda:0', grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# implementation\n",
    "for step in range(1,num_steps):\n",
    "    content_features = nst_model(content_img)\n",
    "    style_features = nst_model(style_img)\n",
    "    gen_features = nst_model(gen_img)\n",
    "    content_loss = 0\n",
    "    style_loss = 0\n",
    "    \n",
    "    for content_feats, style_feats, gen_feats in zip(content_features, style_features, gen_features):  # zip just merges the lists    \n",
    "        batch_size, num_channels, height, width = gen_feats.shape # output related to the 1,2,3,4,5 conv layers  \n",
    "        \n",
    "        content_loss+= torch.mean((content_feats-gen_feats)**2)\n",
    "        # calculate the gram matrices\n",
    "        G = gen_feats.view(num_channels, height*width).mm(gen_feats.view(num_channels, height*width).t())  # similar to reshaping but first a copy is created \n",
    "        S = style_feats.view(num_channels, height*width).mm(style_feats.view(num_channels, height*width).t())\n",
    "        style_loss+= torch.mean((G-S)**2)\n",
    "        \n",
    "    total_loss = alpha*content_loss + beta*style_loss\n",
    "    optimizer.zero_grad()\n",
    "    total_loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    if step%200==0:\n",
    "        print(total_loss)\n",
    "        save_image(gen_img, \"gen.png\") \n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
